{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGANModi.ipynb",
      "provenance": [],
      "mount_file_id": "18QUp4ST7uTpwocf36KmIOv2gZVbsmOLr",
      "authorship_tag": "ABX9TyNAHvkBCercwWVcySZYSsDr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaiSan2001/DeepLearning_StudyLibrary/blob/main/SRGAN/SRGANModi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4giLkKJAHBp",
        "outputId": "85d489da-0961-45b1-a4be-07eed0b83da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Path Initialization#\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/My Drive/Deeplearning/SRGAN')\n",
        "os.chdir('/content/drive/MyDrive/Deeplearning/SRGAN/Keras-SRGAN')\n",
        "os.getcwd()\n",
        "\n",
        "#Library Initialization#\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from skimage import data, io, filters\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy.random import randint\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense, UpSampling2D, Input, Conv2D, Conv2DTranspose, LeakyReLU, PReLU, add\n",
        ")\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modules Declaration#\n",
        "\n",
        "# Residual block\n",
        "def res_block_gen(model, kernal_size, filters, strides):\n",
        "    gen = model\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    # Using Parametric ReLU\n",
        "    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    model = add([gen, model])\n",
        "    return model    \n",
        "    \n",
        "def up_sampling_block(model, kernal_size, filters, strides):   \n",
        "    # In place of Conv2D and UpSampling2D we can also use Conv2DTranspose (Both are used for Deconvolution)\n",
        "    # Even we can have our own function for deconvolution (i.e one made in Utils.py)\n",
        "    #model = Conv2DTranspose(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
        "    model = UpSampling2D(size = 2)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)   \n",
        "    return model\n",
        "\n",
        "def discriminator_block(model, filters, kernel_size, strides):    \n",
        "    model = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = \"same\")(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    model = LeakyReLU(alpha = 0.2)(model)   \n",
        "    return model\n",
        "\n",
        "# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n",
        "class Generator(object):\n",
        "\n",
        "    def __init__(self, noise_shape):\n",
        "        \n",
        "        self.noise_shape = noise_shape\n",
        "\n",
        "    def generator(self):\n",
        "        \n",
        "\t    gen_input = Input(shape = self.noise_shape)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(gen_input)\n",
        "\t    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "\t    \n",
        "\t    gen_model = model\n",
        "        \n",
        "        # Using 16 Residual Blocks\n",
        "\t    for index in range(16):\n",
        "\t        model = res_block_gen(model, 3, 64, 1)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(model)\n",
        "\t    model = BatchNormalization(momentum = 0.5)(model)\n",
        "\t    model = add([gen_model, model])\n",
        "\t    \n",
        "\t    # Using 2 UpSampling Blocks\n",
        "\t    for index in range(2):\n",
        "\t        model = up_sampling_block(model, 3, 256, 1)\n",
        "\t    \n",
        "\t    model = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(model)\n",
        "\t    model = Activation('tanh')(model)\n",
        "\t   \n",
        "\t    generator_model = Model(inputs = gen_input, outputs = model)\n",
        "        \n",
        "\t    return generator_model\n",
        "\n",
        "# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n",
        "class Discriminator(object):\n",
        "\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "    \n",
        "    def discriminator(self):\n",
        "        \n",
        "        dis_input = Input(shape = self.image_shape)\n",
        "        \n",
        "        model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(dis_input)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "        \n",
        "        model = discriminator_block(model, 64, 3, 2)\n",
        "        model = discriminator_block(model, 128, 3, 1)\n",
        "        model = discriminator_block(model, 128, 3, 2)\n",
        "        model = discriminator_block(model, 256, 3, 1)\n",
        "        model = discriminator_block(model, 256, 3, 2)\n",
        "        model = discriminator_block(model, 512, 3, 1)\n",
        "        model = discriminator_block(model, 512, 3, 2)\n",
        "        \n",
        "        model = Flatten()(model)\n",
        "        model = Dense(1024)(model)\n",
        "        model = LeakyReLU(alpha = 0.2)(model)\n",
        "       \n",
        "        model = Dense(1)(model)\n",
        "        model = Activation('sigmoid')(model) \n",
        "        \n",
        "        discriminator_model = Model(inputs = dis_input, outputs = model)\n",
        "        \n",
        "        return discriminator_model\n",
        "\n",
        "class VGG_LOSS(object):\n",
        "\n",
        "    def __init__(self, image_shape):\n",
        "        \n",
        "        self.image_shape = image_shape\n",
        "\n",
        "    # computes VGG loss or content loss\n",
        "    def vgg_loss(self, y_true, y_pred):\n",
        "    \n",
        "        vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=self.image_shape)\n",
        "        vgg19.trainable = False\n",
        "        # Make trainable as False\n",
        "        for l in vgg19.layers:\n",
        "            l.trainable = False\n",
        "        model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
        "        model.trainable = False\n",
        "    \n",
        "        return K.mean(K.square(model(y_true) - model(y_pred)))\n",
        "\n",
        "def get_optimizer():\n",
        " \n",
        "    adam = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "    return adam\n",
        "\n",
        "# Subpixel Conv will upsample from (h, w, c) to (h/r, w/r, c/r^2)\n",
        "def SubpixelConv2D(input_shape, scale=4):\n",
        "    def subpixel_shape(input_shape):\n",
        "        dims = [input_shape[0],input_shape[1] * scale,input_shape[2] * scale,int(input_shape[3] / (scale ** 2))]\n",
        "        output_shape = tuple(dims)\n",
        "        return output_shape\n",
        "    \n",
        "    def subpixel(x):\n",
        "        return tf.depth_to_space(x, scale)\n",
        "        \n",
        "    return Lambda(subpixel, output_shape=subpixel_shape)\n",
        "    \n",
        "# Takes list of images and provide HR images in form of numpy array\n",
        "def hr_images(images):\n",
        "    images_hr = array(images)\n",
        "    return images_hr\n",
        "\n",
        "# Takes list of images and provide LR images in form of numpy array\n",
        "def lr_images(images_real , downscale):\n",
        "    \n",
        "    images= []\n",
        "    for img in  range(len(images_real)):\n",
        "        #images.append(cv2.resize(images_real[img], [images_real[img].shape[0]//downscale,images_real[img].shape[1]//downscale], interpolation='bicubic', mode=None))\n",
        "        im123=cv2.resize(images_real[img], (int(images_real[img].shape[0]//downscale),int(images_real[img].shape[1]//downscale)))\n",
        "        images.append(im123)\n",
        "    images_lr = array(images)\n",
        "    return images_lr\n",
        "    \n",
        "def normalize(input_data):\n",
        "\n",
        "    return (input_data.astype(np.float32) - 127.5)/127.5 \n",
        "    \n",
        "def denormalize(input_data):\n",
        "    input_data = (input_data + 1) * 127.5\n",
        "    return input_data.astype(np.uint8)\n",
        "'''\n",
        "def load_training_data(x_train,y_train,x_test,y_test):\n",
        "\n",
        "    x_train_hr = hr_images(x_train)\n",
        "    x_train_hr = normalize(x_train_hr)\n",
        "    \n",
        "    x_train_lr = lr_images(x_train, 4)\n",
        "    x_train_lr = normalize(x_train_lr)\n",
        "    \n",
        "    x_test_hr = hr_images(x_test)\n",
        "    x_test_hr = normalize(x_test_hr)\n",
        "    \n",
        "    x_test_lr = lr_images(x_test, 4)\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_train_lr, x_train_hr, x_test_lr, x_test_hr\n",
        "    '''\n",
        "def load_training_data(x_train,y_train,x_test,y_test):\n",
        "\n",
        "    x_train_hr = y_train\n",
        "    x_train_hr = normalize(x_train_hr)\n",
        "    \n",
        "    x_train_lr = x_train\n",
        "    x_train_lr = normalize(x_train_lr)\n",
        "    \n",
        "    x_test_hr = y_test\n",
        "    x_test_hr = normalize(x_test_hr)\n",
        "    \n",
        "    x_test_lr = x_test\n",
        "    x_test_lr = normalize(x_test_lr)\n",
        "    \n",
        "    return x_train_lr, x_train_hr, x_test_lr, x_test_hr\n",
        "\n",
        "\n",
        "\n",
        "# While training save generated image(in form LR, SR, HR)\n",
        "# Save only one image as sample  \n",
        "def plot_generated_images(output_dir, epoch, generator, x_test_hr, x_test_lr , dim=(1, 3), figsize=(15, 5)):\n",
        "    print(\"In plot test generated images\")\n",
        "    examples = x_test_hr.shape[0]\n",
        "    print(examples)\n",
        "    value = randint(0, examples)\n",
        "    image_batch_hr = denormalize(x_test_hr)\n",
        "    image_batch_lr = x_test_lr\n",
        "    gen_img = generator.predict(image_batch_lr)\n",
        "    generated_image = denormalize(gen_img)\n",
        "    image_batch_lr = denormalize(image_batch_lr)\n",
        "    \n",
        "    plt.figure(figsize=figsize)\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 1)\n",
        "    plt.imshow(image_batch_lr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "        \n",
        "    plt.subplot(dim[0], dim[1], 2)\n",
        "    plt.imshow(generated_image[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(dim[0], dim[1], 3)\n",
        "    plt.imshow(image_batch_hr[value], interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_dir + 'generated_image_%d.png' % epoch)"
      ],
      "metadata": {
        "id": "6hYZ5jj9CNMr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(10)\n",
        "# Better to use downscale factor as 4\n",
        "downscale_factor = 1\n",
        "# Remember to change image shape if you are having different size of images\n",
        "image_shape = (512,511,3) #(32,32,3)\n",
        "\n",
        "# Combined network\n",
        "def get_gan_network(discriminator, shape, generator, optimizer, vgg_loss):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=shape)\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x) #Here I think there should be two inputs to discriminator x and another hr image\n",
        "    # and like this only the discriminator model should also be modified\n",
        "    gan = Model(inputs=gan_input, outputs=[x,gan_output])    #And why is there two outputs of the gan_model overall\n",
        "    gan.compile(loss=[vgg_loss, \"binary_crossentropy\"],\n",
        "                loss_weights=[1., 1e-3],\n",
        "                optimizer=optimizer)\n",
        "    gan.run_eagerly = True\n",
        "    return gan\n",
        "\n",
        "# default values for all parameters are given, if want defferent values you can give via commandline\n",
        "# for more info use $python train.py -h\n",
        "def train(epochs, batch_size, x_train,y_train,x_test,y_test, model_save_dir):\n",
        "    \n",
        "    x_train_lr, x_train_hr, x_test_lr, x_test_hr = load_training_data(x_train,y_train,x_test,y_test) \n",
        "    loss = VGG_LOSS(image_shape)  \n",
        "    \n",
        "    batch_count = int(x_train_hr.shape[0] / batch_size)\n",
        "    shape = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
        "    \n",
        "    generator = Generator(shape).generator()\n",
        "    discriminator = Discriminator(image_shape).discriminator()\n",
        "\n",
        "    optimizer = get_optimizer()\n",
        "    generator.compile(loss=loss.vgg_loss, optimizer=optimizer)\n",
        "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
        "    \n",
        "    gan = get_gan_network(discriminator, shape, generator, optimizer, loss.vgg_loss)\n",
        "    #gan.build(shape)\n",
        "    loss_file = open(model_save_dir + 'losses.txt' , 'w+')\n",
        "    loss_file.close()\n",
        "\n",
        "    for e in range(1, epochs+1):\n",
        "        print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        for _ in tqdm(range(batch_count)):\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            \n",
        "            image_batch_hr = x_train_hr[rand_nums]\n",
        "           \n",
        "            image_batch_lr = x_train_lr[rand_nums]\n",
        "            print(image_batch_lr.shape)\n",
        "            generated_images_sr = generator.predict(image_batch_lr)\n",
        "\n",
        "            real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "            fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
        "            \n",
        "            discriminator.trainable = True\n",
        "            \n",
        "            d_loss_real = discriminator.train_on_batch(image_batch_hr, real_data_Y)\n",
        "            d_loss_fake = discriminator.train_on_batch(generated_images_sr, fake_data_Y)\n",
        "            discriminator_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            image_batch_hr = x_train_hr[rand_nums]\n",
        "            image_batch_lr = x_train_lr[rand_nums]\n",
        "\n",
        "            gan_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "            discriminator.trainable = False\n",
        "            gan_loss = gan.train_on_batch(image_batch_lr, [image_batch_hr,gan_Y])\n",
        "            \n",
        "            \n",
        "        print(\"discriminator_loss : %f\" % discriminator_loss)\n",
        "        print(\"gan_loss :\", gan_loss)\n",
        "        gan_loss = str(gan_loss)\n",
        "        \n",
        "        loss_file = open(model_save_dir + 'losses.txt' , 'a')\n",
        "        loss_file.write('epoch%d : gan_loss = %s ; discriminator_loss = %f\\n' %(e, gan_loss, discriminator_loss) )\n",
        "        loss_file.close()\n",
        "\n",
        "        if e == 1 or e % 5 == 0:\n",
        "            plot_generated_images(model_save_dir, e, generator,  x_test_hr, x_test_lr)\n",
        "        if e % 2 == 0:\n",
        "            \n",
        "            generator.save(model_save_dir + 'gen_model%d.h5' % e)       \n",
        "            discriminator.save(model_save_dir + 'dis_model%d.h5' % e)\n",
        "            print(\"Model saved\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hKlkmOzJDT9T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(1, 64, x_train,y_train,x_test,y_test, '/content/drive/My Drive/Deeplearning/SRGAN/Modify/')    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "f4BBKjb0EIqi",
        "outputId": "1c28e215-e4ef-4f5a-c0b2-17f7eff82c75"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 512, 511, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 512, 511, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 2048, 2044, 3).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c0cfdcc606e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/My Drive/Deeplearning/SRGAN/Modify/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-7387adce82e6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size, x_train, y_train, x_test, y_test, model_save_dir)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gan_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m#gan.build(shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mloss_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'losses.txt'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-7387adce82e6>\u001b[0m in \u001b[0;36mget_gan_network\u001b[0;34m(discriminator, shape, generator, optimizer, vgg_loss)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgan_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgan_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Here I think there should be two inputs to discriminator x and another hr image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m# and like this only the discriminator model should also be modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgan_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgan_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#And why is there two outputs of the gan_model overall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshape_as_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m           raise ValueError(\n\u001b[0;32m--> 249\u001b[0;31m               \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m               \u001b[0;34mf'incompatible with the layer: expected axis {axis} '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0;34mf'of input shape to have value {value}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"model_1\" (type Functional).\n\nInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 524288, but received input with shape (None, 8388608)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 2048, 2044, 3), dtype=float32)\n  • training=False\n  • mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10                     #dataset importing \n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train=x_train[0:5000]\n",
        "x_test=x_test[0:800]\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikBGe7iyF495",
        "outputId": "f25de428-8409-4e28-b8ce-bead95cddc4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 32, 32, 3)\n",
            "(50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Pre-cropping#\n",
        "Path = '/content/drive/MyDrive/Deeplearning/SRGAN/Modify'\n",
        "#GroundTruth Cropping#\n",
        "os.chdir(Path+'/Cropped/GT')\n",
        "GTs = sorted(os.listdir(Path+'/ImgLib/GT'))\n",
        "nums1 = len(GTs)\n",
        "for i, name1 in enumerate(GTs):\n",
        "    fpath1 = Path+'/ImgLib/GT/' + name1\n",
        "    image = Image.open(fpath1)\n",
        "    image = np.array(image)\n",
        "    image = image[100:612,:]\n",
        "    image = Image.fromarray(image)\n",
        "\n",
        "    image.save('%s'%name1)\n",
        "\n",
        "#Input Cropping#\n",
        "os.chdir(Path+'/Cropped/Input')\n",
        "Inputs = sorted(os.listdir(Path+'/ImgLib/Input'))\n",
        "nums1 = len(Inputs)\n",
        "for i, name2 in enumerate(GTs):\n",
        "    fpath2 = Path+'/ImgLib/Input/' + name2\n",
        "    image = Image.open(fpath2)\n",
        "    image = np.array(image)\n",
        "    image = image[100:612,:]\n",
        "    image = Image.fromarray(image)\n",
        "\n",
        "    image.save('%s'%name2)"
      ],
      "metadata": {
        "id": "uWynWWFwcHLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Set Preparation#\n",
        "TrainPath = '/content/drive/MyDrive/Deeplearning/SRGAN/Modify/Cropped'\n",
        "Input_set = []\n",
        "GT_set =[]\n",
        "\n",
        "#Random Selection for Cross-Validation#\n",
        "GTs = sorted(os.listdir(TrainPath+'/GT'))\n",
        "for gt in GTs:\n",
        "    #find the GT image\n",
        "    fpath1 = TrainPath + '/GT/' + gt #Read in the file one by one\n",
        "    gt_img = cv2.imread(fpath1, cv2.IMREAD_COLOR)\n",
        "    #print(gt_img.shape)\n",
        "\n",
        "    #find the corresponding Input image\n",
        "    fpath2 = TrainPath +'/Input/' + gt\n",
        "    Input_img = cv2.imread(fpath2, cv2.IMREAD_COLOR)\n",
        "\n",
        "    #Storage\n",
        "    GT_set.append(gt_img)\n",
        "    Input_set.append(Input_img)\n",
        "    \n",
        "GT_set = np.array(GT_set, dtype=np.float32)\n",
        "Input_set = np.array(Input_set, dtype=np.float32)\n",
        "\n",
        "print(GT_set.shape)\n",
        "print(Input_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8zGYw0QkyqT",
        "outputId": "b091d460-163d-427f-fa5c-f2e05c4d6e5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 512, 511, 3)\n",
            "(100, 512, 511, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.array(Input_set[0:80], dtype=np.float32)\n",
        "x_test=np.array(Input_set[80:], dtype=np.float32)\n",
        "y_train=np.array(GT_set[0:80], dtype=np.float32)\n",
        "y_test=np.array(GT_set[80:], dtype=np.float32)\n",
        "print(x_train.shape);print(x_test.shape)\n",
        "print(y_train.shape);print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u149Lli6EP7i",
        "outputId": "9105f526-733d-484c-9a5e-614bb2119280"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80, 512, 511, 3)\n",
            "(20, 512, 511, 3)\n",
            "(80, 512, 511, 3)\n",
            "(20, 512, 511, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_lr1, x_train_hr1, x_test_lr1, x_test_hr1 = load_training_data(x_train,y_train,x_test,y_test)\n",
        "print(x_train_lr1.shape)\n",
        "print(x_train_hr1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x99gtvr4r2S4",
        "outputId": "5199e4fa-83ed-4227-8322-2b3430858ca9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80, 512, 511, 3)\n",
            "(80, 512, 511, 3)\n"
          ]
        }
      ]
    }
  ]
}